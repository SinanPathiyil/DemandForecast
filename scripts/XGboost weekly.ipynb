{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d359fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import random, numpy as np\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804ecfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_excel('../data/demand_prediction_weekly.xlsx')  # <-- change path if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7b35a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "medicine_name = 'MONTEMAC FX TAB'\n",
    "df_med = df[df['Product_Name'] == medicine_name].copy()\n",
    "\n",
    "# Sort by week\n",
    "#df_med = df_med.sort_values('Week')\n",
    "df = df.sort_values('Week').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5707bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_med.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea7a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Derive Approximate Month ----\n",
    "# Since there are ~4.3 weeks per month, convert week number to month roughly\n",
    "df_med['Month'] = np.ceil(df_med['Week_Number'] / 4.33).astype(int)\n",
    "df_med['Month'] = df_med['Month'].clip(upper=12)\n",
    "\n",
    "\n",
    "# ---- Derive Quarter ----\n",
    "df_med['Quarter'] = ((df_med['Month'] - 1) // 3 + 1).astype(int)\n",
    "\n",
    "# ---- Flags for Year Start/End ----\n",
    "df_med['Is_Year_Start'] = (df_med['Week_Number'] <= 4).astype(int)\n",
    "df_med['Is_Year_End'] = (df_med['Week_Number'] >= 48).astype(int)\n",
    "\n",
    "df_med['Sin_Week'] = np.sin(2 * np.pi * df_med['Week_Number'] / 52)\n",
    "df_med['Cos_Week'] = np.cos(2 * np.pi * df_med['Week_Number'] / 52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d050bbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61c6c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lag in range(1, 13):  # 12 weeks (3 months)\n",
    "    df_med[f'lag_{lag}'] = df_med['Total_Quantity'].shift(lag)\n",
    "\n",
    "df_med['rolling_mean_3'] = df_med['Total_Quantity'].shift(1).rolling(window=3).mean()\n",
    "df_med['rolling_mean_5'] = df_med['Total_Quantity'].shift(1).rolling(window=5).mean()\n",
    "\n",
    "\n",
    "\n",
    "df_med['rolling_mean_6'] = df_med['Total_Quantity'].shift(1).rolling(6).mean()\n",
    "df_med['rolling_std_6'] = df_med['Total_Quantity'].shift(1).rolling(6).std()\n",
    "\n",
    "\n",
    "df_med['rolling_mean_8'] = df_med['Total_Quantity'].shift(1).rolling(window=8).mean()\n",
    "df_med['rolling_std_4'] = df_med['Total_Quantity'].shift(1).rolling(window=4).std()\n",
    "\n",
    "df_med = df_med.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6e5122",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_med.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbd3d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import TRUE\n",
    "\n",
    "from sympy import false\n",
    "\n",
    "\n",
    "X_med = df_med.drop(columns=['Total_Quantity', 'Week', 'Product_Name'])\n",
    "y_med = df_med['Total_Quantity']\n",
    "\n",
    "# Drop non-numeric columns if any\n",
    "#X_med = X_med.apply(pd.to_numeric, errors='ignore')\n",
    "#non_numeric_cols = X_med.select_dtypes(include=['object']).columns\n",
    "#if len(non_numeric_cols) > 0:\n",
    "#    X_med = X_med.drop(columns=non_numeric_cols)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_med, y_med, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "#X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "#    X_train, y_train, test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26757b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "a = X_train\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f43bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076db17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "| Parameter        | Meaning           | Effect                  | Typical Range |\n",
    "| ---------------- | ----------------- | ----------------------- | ------------- |\n",
    "| n_estimators     | number of trees   | More trees = better fit | 300â€“1000      |\n",
    "| learning_rate    | Step size         | Lower = more stable     | 0.01â€“0.1      |\n",
    "| max_depth        | Tree depth        | Higher = more complex   | 3â€“10          |\n",
    "| subsample        | Row sampling      | Prevents overfitting    | 0.5â€“1.0       |\n",
    "| colsample_bytree | Column sampling   | Prevents overfitting    | 0.6â€“1.0       |\n",
    "| min_child_weight | Min data per leaf | Higher = simpler        | 1â€“10          |\n",
    "| gamma            | Split threshold   | Higher = conservative   | 0â€“1           |\n",
    "| reg_lambda       | L2 regularization | Higher = less overfit   | 0.1â€“10        |\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "model = XGBRegressor(\n",
    "    objective= \"reg:squarederror\",  # reg:squarederror,  reg:absoluteerror  use if there are sudden hikes\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=4,\n",
    "    subsample=1,\n",
    "    colsample_bytree=1,\n",
    "    min_child_weight=1,\n",
    "    gamma=0.1,\n",
    "    reg_lambda=1.0,\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "shift_weeks = 2  # number of weeks to shift\n",
    "\n",
    "# Align predictions and actuals\n",
    "aligned_y_pred = y_pred[shift_weeks:]      # drop first 'shift_weeks' predictions\n",
    "aligned_y_test = y_test[:-shift_weeks]     # drop last 'shift_weeks' actuals\n",
    "\n",
    "# Compute metrics\n",
    "mae = mean_absolute_error(aligned_y_test, aligned_y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(aligned_y_test, aligned_y_pred))\n",
    "r2 = r2_score(aligned_y_test, aligned_y_pred)\n",
    "\n",
    "print(f\"MAE (aligned): {mae:.2f}\")\n",
    "print(f\"RMSE (aligned): {rmse:.2f}\")\n",
    "print(f\"RÂ² (aligned): {r2:.2f}\")\n",
    "\n",
    "final_xgb = model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b340235",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "model = XGBRegressor(\n",
    "    objective=\"reg:absoluteerror\",     # still best for handling spikes\n",
    "    n_estimators=600,                  # slightly fewer trees â†’ faster & smoother\n",
    "    learning_rate=0.05,                # reacts faster to changes\n",
    "    max_depth=6,                       # slightly deeper for better short-term sensitivity\n",
    "    subsample=0.8,                     # more training data per tree â†’ stronger trends\n",
    "    colsample_bytree=0.8,              # keeps moderate feature randomness\n",
    "    min_child_weight=2,                # a bit lower to allow finer local splits\n",
    "    gamma=0.15,                        # mild penalty for complexity\n",
    "    reg_lambda=1.5,                    # moderate L2 regularization\n",
    "    reg_alpha=0.3,                     # slightly less L1 regularization (more flexibility)\n",
    "    random_state=42\n",
    ")\n",
    "for MEFORNIX P\n",
    "\n",
    "\n",
    "model = XGBRegressor(\n",
    "    objective= \"reg:squarederror\",  # reg:squarederror,  reg:absoluteerror  use if there are sudden hikes\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=4,\n",
    "    subsample=1,\n",
    "    colsample_bytree=1,\n",
    "    min_child_weight=1,\n",
    "    gamma=0.1,\n",
    "    reg_lambda=1.0,\n",
    ")\n",
    "MAE (aligned): 11.70\n",
    "RMSE (aligned): 15.51\n",
    "RÂ² (aligned): 0.54\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = XGBRegressor(\n",
    "    objective= \"reg:squarederror\",  # reg:squarederror,  reg:absoluteerror  use if there are sudden hikes\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=4,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    min_child_weight=1,\n",
    "    gamma=0.1,\n",
    "    reg_lambda=1.0,\n",
    ")\n",
    "\n",
    "\n",
    "model = XGBRegressor(\n",
    "    objective= \"reg:squarederror\",  # reg:squarederror,  reg:absoluteerror  use if there are sudden hikes\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=4,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    min_child_weight=1,\n",
    "    gamma=0.1,\n",
    "    reg_lambda=1.5,\n",
    ")\n",
    "\n",
    "\n",
    "{'subsample': 0.9, 'reg_lambda': 1.5, 'reg_alpha': 0, 'n_estimators': 500, 'min_child_weight': 1, 'max_depth': 8, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 1.0}\n",
    "{'subsample': 0.8, 'reg_lambda': 2, 'reg_alpha': 0.5, 'n_estimators': 400, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.05, 'gamma': 0, 'colsample_bytree': 0.8}\n",
    "\n",
    "\n",
    "model = XGBRegressor(\n",
    "    n_estimators=800,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=6,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    gamma=0.1,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model = XGBRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=4,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    min_child_weight=1,\n",
    "    gamma=0.1,\n",
    "    random_state=42,\n",
    "    reg_lambda=2.0,\n",
    "    reg_alpha=0.5\n",
    ")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16514a6",
   "metadata": {},
   "source": [
    "PLOTTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14acc21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "shift_weeks = 2  # shift prediction backward based on lag features\n",
    "\n",
    "\n",
    "\n",
    "# ðŸŸ¦ TEST SET (Shifted) PLOT\n",
    "\n",
    "# Week labels for test set\n",
    "week_labels = df_med.loc[y_test.index, 'Week'].astype(str).values\n",
    "\n",
    "# Shift predicted demand backward\n",
    "shifted_pred = y_pred[shift_weeks:]          # drop first 'shift_weeks' predictions\n",
    "shifted_weeks = week_labels[:-shift_weeks]   # drop last 'shift_weeks' weeks to align\n",
    "\n",
    "# Align actual demand\n",
    "aligned_y_test = y_test.iloc[:-shift_weeks]   # drop last 'shift_weeks' weeks\n",
    "aligned_weeks = week_labels[:-shift_weeks]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(aligned_weeks, aligned_y_test.values, color='blue', label='Actual Demand', linewidth=2)\n",
    "plt.plot(aligned_weeks, shifted_pred, color='orange', linestyle='--', label='Predicted Demand (Shifted)', linewidth=2)\n",
    "\n",
    "plt.title(f'ðŸ”¸ Forecasting for {medicine_name} (Shifted Test Predictions)', fontsize=13)\n",
    "plt.xlabel('Week', fontsize=11)\n",
    "plt.ylabel('Quantity', fontsize=11)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ðŸŸ© FULL DATA (Train + Test + Shifted)\n",
    "\n",
    "# Prepare actual full data\n",
    "all_weeks = df_med['Week'].astype(str).values\n",
    "all_actuals = df_med['Total_Quantity'].values\n",
    "\n",
    "# Remove last 'shift_weeks' weeks of actual data (since predictions shifted)\n",
    "all_weeks_trimmed = all_weeks[:-shift_weeks]\n",
    "all_actuals_trimmed = all_actuals[:-shift_weeks]\n",
    "\n",
    "# Training predictions\n",
    "train_weeks = df_med.loc[y_train.index, 'Week'].astype(str).values\n",
    "train_preds = model.predict(X_train)\n",
    "\n",
    "# Test predictions (shifted)\n",
    "test_weeks = df_med.loc[y_test.index, 'Week'].astype(str).values\n",
    "shifted_pred = y_pred[shift_weeks:]\n",
    "shifted_test_weeks = test_weeks[:-shift_weeks]\n",
    "\n",
    "# Plot all together\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.plot(all_weeks_trimmed, all_actuals_trimmed, color='blue', label='Actual Demand', linewidth=2)\n",
    "plt.plot(train_weeks, train_preds, color='green', linestyle='--', label='Training Prediction', linewidth=2)\n",
    "plt.plot(shifted_test_weeks, shifted_pred, color='orange', linestyle='--', label='Test Prediction (Aligned)', linewidth=2)\n",
    "\n",
    "plt.title(f'ðŸ“ˆ Full Data Forecasting for {medicine_name} (Train + Test)', fontsize=14)\n",
    "plt.xlabel('Week', fontsize=11)\n",
    "plt.ylabel('Quantity', fontsize=11)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6a9ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(a.columns, model.feature_importances_)\n",
    "plt.title(\"Feature Importance - XGBoost\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d04e70",
   "metadata": {},
   "source": [
    "MODEL SAVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825a5b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model.save_model(f\"../saved models/xgboost_{medicine_name}.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ff1676",
   "metadata": {},
   "source": [
    "RANDOMIZED SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0591bf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================\n",
    "# ðŸ” RandomizedSearchCV Setup\n",
    "# ============================\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 300, 400, 500, 800],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7, 8, 10],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0, 0.5, 1],\n",
    "    'reg_lambda': [0.5, 1, 1.5, 2]\n",
    "}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    cv=tscv,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nâœ… Best Parameters Found:\")\n",
    "print(search.best_params_)\n",
    "print(f\"ðŸ† Best CV MAE: {abs(search.best_score_):.2f}\")\n",
    "\n",
    "# ============================\n",
    "# ðŸš€ Retrain with Best Params\n",
    "# ============================\n",
    "best_params = search.best_params_\n",
    "\n",
    "final_xgb = XGBRegressor(**best_params, objective='reg:squarederror', random_state=42)\n",
    "\n",
    "final_xgb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# ðŸ“ˆ Predict & Align by 2 Weeks\n",
    "# ============================\n",
    "y_pred = final_xgb.predict(X_test)\n",
    "\n",
    "shift_weeks = 2  # shift predicted backward (t-2)\n",
    "aligned_y_pred = y_pred[shift_weeks:]\n",
    "aligned_y_test = y_test[:-shift_weeks]\n",
    "\n",
    "# ============================\n",
    "# ðŸ“Š Metrics\n",
    "# ============================\n",
    "mae = mean_absolute_error(aligned_y_test, aligned_y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(aligned_y_test, aligned_y_pred))\n",
    "r2 = r2_score(aligned_y_test, aligned_y_pred)\n",
    "\n",
    "print(\"\\nðŸ“Š Final Model Performance (Aligned by 2 Weeks):\")\n",
    "print(f\"MAE:  {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"RÂ²:   {r2:.2f}\")\n",
    "\n",
    "# ============================\n",
    "# ðŸ“‰ Plot\n",
    "# ============================\n",
    "test_weeks = df_med.loc[y_test.index, 'Week'].astype(str).values\n",
    "aligned_weeks = test_weeks[:-shift_weeks]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(aligned_weeks, aligned_y_test.values, color='blue', label='Actual Demand', linewidth=2)\n",
    "plt.plot(aligned_weeks, aligned_y_pred, color='orange', linestyle='--', label='Predicted Demand', linewidth=2)\n",
    "\n",
    "plt.title(f'Forecast for {medicine_name} (Aligned by 2 Weeks)', fontsize=14)\n",
    "plt.xlabel('Week', fontsize=11)\n",
    "plt.ylabel('Quantity', fontsize=11)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7910de9c",
   "metadata": {},
   "source": [
    "MODEL PREDICTION FOR NEXT TWO MONTHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82162a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next 2 months prediction (~9 weeks) using iterative lag-features\n",
    "n_weeks = 9  # ~2 months (4.33 weeks/month -> ~8.66 -> 9)\n",
    "last_row = df_med.iloc[-1]\n",
    "start_year = int(last_row['Year'])\n",
    "start_week = int(last_row['Week_Number'])\n",
    "\n",
    "# initialize prev values (most recent first) from last 12 real observations\n",
    "prev_qty = list(df_med['Total_Quantity'].astype(float).values[-12:][::-1])  # lag_1 = prev_qty[0]\n",
    "\n",
    "preds = []\n",
    "pred_weeks = []\n",
    "\n",
    "for i in range(n_weeks):\n",
    "    # compute year/week (simple rollover at 53)\n",
    "    wk = start_week + i + 1\n",
    "    yr = start_year\n",
    "    while wk > 53:\n",
    "        wk -= 53\n",
    "        yr += 1\n",
    "\n",
    "    month = int(np.ceil(wk / 4.33))\n",
    "    month = min(month, 12)\n",
    "    quarter = ((month - 1) // 3) + 1\n",
    "    is_year_start = int(wk <= 4)\n",
    "    is_year_end = int(wk >= 48)\n",
    "    sin_week = np.sin(2 * np.pi * wk / 52)\n",
    "    cos_week = np.cos(2 * np.pi * wk / 52)\n",
    "\n",
    "    # prepare lag features (ensure we have 12 entries in prev_qty)\n",
    "    lags = {f'lag_{j}': (prev_qty[j-1] if j-1 < len(prev_qty) else 0.0) for j in range(1, 13)}\n",
    "\n",
    "    # rolling features based on previous values (exclude current)\n",
    "    def safe_mean(arr, k):\n",
    "        vals = arr[:k] if len(arr) >= 1 else [0.0]\n",
    "        return float(np.mean(vals[:k])) if len(vals) >= 1 else 0.0\n",
    "\n",
    "    def safe_std(arr, k):\n",
    "        vals = arr[:k]\n",
    "        if len(vals) <= 1:\n",
    "            return 0.0\n",
    "        return float(np.std(vals[:k], ddof=1))\n",
    "\n",
    "    rm3 = safe_mean(prev_qty, 3)\n",
    "    rm5 = safe_mean(prev_qty, 5)\n",
    "    rm6 = safe_mean(prev_qty, 6)\n",
    "    rs6 = safe_std(prev_qty, 6)\n",
    "    rm8 = safe_mean(prev_qty, 8)\n",
    "    rs4 = safe_std(prev_qty, 4)\n",
    "\n",
    "    # build feature row matching 'a' columns order\n",
    "    row = {\n",
    "        'Year': yr,\n",
    "        'Week_Number': wk,\n",
    "        'Month': month,\n",
    "        'Quarter': quarter,\n",
    "        'Is_Year_Start': is_year_start,\n",
    "        'Is_Year_End': is_year_end,\n",
    "        'Sin_Week': sin_week,\n",
    "        'Cos_Week': cos_week,\n",
    "        **lags,\n",
    "        'rolling_mean_3': rm3,\n",
    "        'rolling_mean_5': rm5,\n",
    "        'rolling_mean_6': rm6,\n",
    "        'rolling_std_6': rs6,\n",
    "        'rolling_mean_8': rm8,\n",
    "        'rolling_std_4': rs4\n",
    "    }\n",
    "\n",
    "    feat_df = pd.DataFrame([row])\n",
    "    # ensure same column order as training features\n",
    "    feat_df = feat_df[a.columns]\n",
    "\n",
    "    # scale and predict\n",
    "    X_future = scaler.transform(feat_df)\n",
    "    pred = final_xgb.predict(X_future)[0]\n",
    "    preds.append(float(pred))\n",
    "    pred_weeks.append(f\"{yr}-W{wk:02d}\")\n",
    "\n",
    "    # update prev_qty (most recent first)\n",
    "    prev_qty.insert(0, float(pred))\n",
    "    prev_qty = prev_qty[:12]  # keep last 12\n",
    "\n",
    "# show results\n",
    "future_df = pd.DataFrame({'Week': pred_weeks, 'Predicted_Quantity': np.round(preds, 2)})\n",
    "print(future_df)\n",
    "\n",
    "# optional quick plot\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(all_weeks_trimmed[-12:], all_actuals_trimmed[-12:], marker='o', label='Last 12 Actuals')\n",
    "plt.plot(pred_weeks, preds, marker='o', linestyle='--', label='Next 2 Months (Predicted)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Quantity')\n",
    "plt.title(f'Next {n_weeks} Weeks Forecast for {medicine_name}')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
